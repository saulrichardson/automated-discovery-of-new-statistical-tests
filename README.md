# Statistical Test Discovery & Formal Verification Framework

## Tableâ€¯ofâ€¯Contents

1. [Motivation & Firstâ€‘Principles Vision](#motivation)
2. [Problem Statement](#problem)
3. [Endâ€‘toâ€‘End Workflow](#workflow)
4. [Module Specifications](#modules)

   * 4.1 [Searchâ€‘Space API](#search)
   * 4.2 [Simulation Engine](#sim)
   * 4.3 [RL Optimisation Loop](#rl)
   * 4.4 [Calibration & Criticalâ€‘Value Estimation](#calib)
   * 4.5 [Formal Proof Layer](#proof)
   * 4.6 [Continuous Integration & Reproducibility](#ci)
5. [Prototype: Rediscovering the *z*â€‘Test](#protoâ€‘z)
6. [Path to a Unitâ€‘Root (ADFâ€‘like) Test](#protoâ€‘adf)
7. [Tech Stack](#tech)
8. [Repository Layout](#repo)
9. [Contribution Guide](#contrib)
10. [Roadâ€‘Map & Open Questions](#roadmap)
11. [Glossary](#glossary)
12. [Key References](#refs)

---

<a name="motivation"></a>

## 1. Motivation & Firstâ€‘Principles Vision

> **Goal:** Build an open, reproducible pipeline that *discovers* powerful statistical tests from raw simulated data and then *certifies* them with machineâ€‘checked proofs.
>
> **First Principle:**  A statistical test is valuable when it simultaneously (i) controls the Typeâ€‘I error for **all** distributions in a null model and (ii) achieves high power for realistic alternatives.  Nothing in classical theory prevents novel testsâ€”*if* we can search the infinite design space and give ironâ€‘clad guarantees.
>
> **Thought Experiment:**  Imagine the Augmented Dickeyâ€“Fuller (ADF) or the classical *z*â€‘test had never been written down.  Our framework should be capable of rediscovering an equivalent (or better) procedureâ€”*purely* by simulationâ€‘driven searchâ€”**and** output a Leanâ€‘verified theorem that its size â‰¤â€¯Î±.

---

<a name="problem"></a>

## 2. Problem Statement

Given:

* A **null family** ğ’«â‚€ (e.g. all I(1) processes, or all i.i.d. samples with meanÂ 0).
* A set of **alternative generators** ğ’«â‚ (e.g. stationary AR processes, or meanâ€‘shifted normals).
* A target significance level Î± (e.g.Â 0.05).

We seek an algorithm that outputs a pair *(TÌ‚,Â cÌ‚\_Î±)* such that

1. *(Validity)*Â âˆ€â€¯PÂ âˆˆÂ ğ’«â‚€:Â P\[TÌ‚(X)Â >Â cÌ‚\_Î±]Â â‰¤Â Î±.
2. *(High Power)*Â âˆ€â€¯fixedÂ PÂ âˆˆÂ ğ’«â‚:Â P\[TÌ‚(X)Â >Â cÌ‚\_Î±]Â â†’Â 1 as nÂ â†’Â âˆ.

---

<a name="workflow"></a>

## 3. Endâ€‘toâ€‘End Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   samples   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   reward   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Simulatorâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   RL/ES    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Î¸_t    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â–²                   â–²   â–²                      â”‚
      â”‚ null / alt        â”‚   â”‚                      â”‚ T_Î¸(X)
      â”‚                   â”‚   â”‚                      â–¼
      â”‚            sizeâ€‘penalty â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤Calibration cv_Î±â”‚
      â”‚                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                                               â”‚
      â”‚                                 Lean proof of â”‚ size â‰¤ Î±
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. **Simulation** draws batches from null & alternative models.
2. **RL / Evolution Search** adjusts parameters Î¸ of a candidate statistic family *T\_Î¸*.
3. **Calibration** computes a critical value *c\_Î±(Î¸)* to keep empirical size near Î±.
4. **Formal Verification** (Lean) proves size control (and ideally consistency) *uniformly* over the whole searchâ€‘space Î˜.
5. **Evaluation** reports finiteâ€‘sample power curves & publishes the certified test.

---

<a name="modules"></a>

## 4. Module Specifications

### <a name="search"></a>4.1 Searchâ€‘SpaceÂ API

* **Definition:**Â A Python class `StatFamily` exposing

  * `T(theta, sample) -> float`
  * `critical_value(theta, alpha, sample_or_n) -> float`
* **Assumptions for Proof:**  For every Î¸ âˆˆ Î˜

  * `T` is measurable; moments up to orderÂ 2 exist.
  * Calibration routine targets Î± via bootstrap/permutation/analytic quantile.
* **Extensibility:**  New statistic families register by subclassing `StatFamily`.

### <a name="sim"></a>4.2 Simulation Engine

* Vectorised NumPy/JAX samplers for null & alt.
* Pluggable noise, lagâ€‘structure, and dependence models.
* CI testâ€‘set ensures deterministic seeds for reproducibility.

### <a name="rl"></a>4.3 RL Optimisation Loop

* **Algorithm:**Â default PPO (SB3) or CMAâ€‘ES (OpenAI Evolution).
* **Reward Function:**

  ```
     r = 1{reject under alt} âˆ’ Î»Â·max(0, reject_under_null âˆ’ Î±)
  ```

  Dualâ€‘gradient step on Î» enforces the size constraint.
* **Parallelism:**Â gymâ€‘vector > 32 envs; Ray for scaleâ€‘out.

### <a name="calib"></a>4.4 Calibration & Criticalâ€‘Value Estimation

* Default: percentile bootstrap with BÂ =Â 2â€¯000.
* Block bootstrap helper for dependent data.
* Guarantees empirical size â‰¤â€¯Î± *by definition*; formal proof extends this to uniform size via consistency of the bootstrap quantile.

### <a name="proof"></a>4.5 Formal Proof Layer

* **Assistant:** LeanÂ 4 + mathlib4 probability.
* **Core Theorem (template):**

  ```lean
  theorem size_control (Î¸ : Î˜) : âˆ€ n, Pâ‚€ (T Î¸ n > cv Î¸ Î± n) â‰¤ Î±
  ```
* **Automation:** APOLLO / DeepSeekâ€‘Prover attempts proof; CI fails if kernel rejects.
* Optional: consistency proof via CLT or martingale SLLN.

### <a name="ci"></a>4.6 Continuous Integration

* GitHub Actions steps:

  1. `python train.py --fast` (short smoke run)
  2. Cache or download preâ€‘trained Î¸Ì‚.
  3. `lean --make proof/` (must pass).
  4. Run unit tests + power benchmarks; upload plots as artefacts.

---

<a name="protoâ€‘z"></a>

## 5. PrototypeÂ 1Â â€“ Rediscovering the *z*â€‘Test

* **Search space:** linear combination of sample mean, variance, skew.
* **nÂ =Â 30**, ÏƒÂ =Â 1 known, Î±Â =Â 0.05.
* **Outcome:** RL converges to Î¸â‰ˆ(âˆšn,â‰ˆ0,â‰ˆ0). Lean proof trivial (bootstrap quantile).  Endâ€‘toâ€‘end runtimeÂ <Â 10â€¯min on CPU.

---

<a name="protoâ€‘adf"></a>

## 6. PrototypeÂ 2Â â€“ Toward an ADFâ€‘like Unitâ€‘Root Test

* **Search space:** studentised OLS tâ€‘ratios on lagged level + kÂ lagged differences.
* **Simulation:** ARIMA(0,1,0) for null; AR(p) Ïâˆˆ{0.6,0.8} for alt.
* **Calibration:** block bootstrap under unitâ€‘root.
* **Proof tasks:** functional CLT for partialâ€‘sum process; validity of block bootstrap (existing theorems in econ library).

---

<a name="tech"></a>

## 7. TechÂ Stack

| Layer      | Libs / Tools                                        |
| ---------- | --------------------------------------------------- |
| Simulation | NumPy, JAX, SciPy, NetworkX                         |
| RL / Optim | Stableâ€‘Baselines3, Ray RLlib, CMAâ€‘ES, Optuna        |
| Proof      | LeanÂ 4, mathlib4, APOLLO / DeepSeekâ€‘Prover          |
| DevOps     | GitHub Actions, Docker, preâ€‘commit, `black`, `ruff` |
| Viz / Eval | Matplotlib, seaborn, pandas, WeightsÂ &Â Biases       |

---

<a name="repo"></a>

## 8. Repository Layout

```
statâ€‘testâ€‘discovery/
â”œâ”€â”€ search/           # RL & ES entryâ€‘points
â”‚Â Â  â”œâ”€â”€ train.py
â”‚Â Â  â””â”€â”€ envs.py
â”œâ”€â”€ statfamily/       # pluggable statistic modules
â”‚Â Â  â”œâ”€â”€ base.py
â”‚Â Â  â””â”€â”€ linear_mean_var.py  # prototype 1
â”œâ”€â”€ proof/            # Lean files
â”‚Â Â  â”œâ”€â”€ Size.lean
â”‚Â Â  â””â”€â”€ Consistency.lean
â”œâ”€â”€ data/             # cached Î¸Ì‚ & CV tables
â”œâ”€â”€ experiments/      # notebooks & plots
â”œâ”€â”€ ci/               # GitHub Action workflows
â””â”€â”€ README.md         # quickâ€‘start & badge
```

---

<a name="contrib"></a>

## 9. Contribution Guide

1. **ForkÂ &Â clone**; install via `poetry install --with dev`.
2. Add a new statistic: subclass `StatFamily`, write a docstring describing assumptions.
3. Provide a minimal Lean lemma file or extend existing theorems.
4. Run `pytest` and `lean --make` locally; open a PR.
5. CI must stay green (training, proofs, lint).

---

<a name="roadmap"></a>

## 10. Roadâ€‘Map & Open Questions

| Milestone                | ETA     | Owner                |
| ------------------------ | ------- | -------------------- |
| Full ADFâ€‘like demo       | Q3Â 2025 | core team            |
| Graph twoâ€‘sample test    | Q4Â 2025 | community            |
| Privacyâ€‘preserving tests | 2026    | TBD                  |
| Isabelle backend         | 2026    | external contributor |

*Open Issues*: heavyâ€‘tail robustness, sequential tests, formalising bootstrap for mixing processes.

---

<a name="glossary"></a>

## 11. Glossary

* **Size (Î±):** maximal Typeâ€‘I error probability.
* **Power:** probability to reject under a specific alternative.
* **Consistency:** powerÂ â†’Â 1 as nÂ â†’Â âˆ.
* **Search space Î˜:** parameter set for candidate statistics.
* **Lean:** theorem prover / proof assistant based on dependent type theory.

---

<a name="refs"></a>

## 12. Key References

1. Dickey, D.Â & Fuller, W.Â (1979) *Distribution of the Estimators for Autoregressive Time Series*.
2. Efron, B.Â (1979) *Bootstrap Methods*.
3. Kirchler,Â Lin etÂ al.Â (2020) *Learning Twoâ€‘Sample Tests via Deep Kernels*.
4. DeepSeekâ€‘Prover TeamÂ (2024), *Largeâ€‘Scale Automated Theorem Proving*.
5. Stableâ€‘Baselines3 docs, RLlib docs, Lean `mathlib4`.

---
